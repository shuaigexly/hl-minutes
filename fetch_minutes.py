import os
import time
import json
import random
import pandas as pd
from datetime import datetime, timedelta
from hyperliquid.info import Info
from hyperliquid.utils.error import ClientError
from config import (
    COINS,
    INTERVALS,
    DATA_DIR,
    CHECKPOINT_FILE,
    CHUNK_HOURS,
    API_SLEEP,
    YEARS_BACK,
)

info = Info(skip_ws=True)

# ----------------------------
# å·¥å…·å‡½æ•°
# ----------------------------

def load_checkpoint():
    if not os.path.exists(CHECKPOINT_FILE):
        return {}
    with open(CHECKPOINT_FILE, "r") as f:
        return json.load(f)

def save_checkpoint(ckpt):
    with open(CHECKPOINT_FILE, "w") as f:
        json.dump(ckpt, f, indent=2)

def safe_call_with_retry(func, max_retries=10, **kwargs):
    """
    é€šç”¨é‡è¯•åŒ…è£…ï¼š
    - ä¸“é—¨å¤„ç† Hyperliquid çš„ 429 é™æµé”™è¯¯
    - å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
    """
    for attempt in range(1, max_retries + 1):
        try:
            # æ­£å¸¸è°ƒç”¨ï¼Œæ¯”å¦‚ func(name=..., interval=..., startTime=..., endTime=...)
            return func(**kwargs)

        except ClientError as e:
            # 429ï¼šrate limit
            if getattr(e, "status_code", None) == 429:
                # æŒ‡æ•°é€€é¿ï¼Œæœ€å¤šç­‰åˆ° 30 ç§’
                sleep_time = min(5 * attempt, 30) + random.uniform(0, 1)
                print(f"âš ï¸  æ”¶åˆ° 429 é™æµï¼Œç¬¬ {attempt}/{max_retries} æ¬¡é‡è¯•ï¼Œä¼‘çœ  {sleep_time:.2f} ç§’...")
                time.sleep(sleep_time)
                continue

            # å…¶ä»–çŠ¶æ€ç ï¼Œç›´æ¥æŠ›å‡ºï¼ˆè¯´æ˜ä¸æ˜¯é™æµï¼Œæ˜¯åˆ«çš„é—®é¢˜ï¼‰
            raise

    raise RuntimeError("è¿ç»­å¤šæ¬¡å›  429 é™æµå¤±è´¥ï¼Œæ”¾å¼ƒæœ¬æ¬¡åŒºé—´ã€‚")

def save_parquet_incremental(path, df_new):
    # å¼ºåˆ¶æŠŠ t / T è½¬æˆ intï¼Œé¿å… datetime ç±»å‹æ··å…¥
    df_new["t"] = df_new["t"].astype("int64")
    df_new["T"] = df_new["T"].astype("int64")

    if os.path.exists(path):
        df_old = pd.read_parquet(path)

        # åŒæ ·å¼ºåˆ¶æ—§æ•°æ®è½¬æ¢ç±»å‹
        df_old["t"] = df_old["t"].astype("int64")
        df_old["T"] = df_old["T"].astype("int64")

        df = pd.concat([df_old, df_new], ignore_index=True)
        df.drop_duplicates(subset=["t"], inplace=True)
        df.sort_values("t", inplace=True)
    else:
        df = df_new

    df.to_parquet(path, index=False)
    print(f"ğŸ’¾ Saved: {path} (rows={len(df)})")



# ----------------------------
# ä¸»å¾ªç¯ï¼šå¤šå¸ç§ + å¤šå‘¨æœŸ
# ----------------------------

def fetch_all():
    ckpt = load_checkpoint()
    now_ms = int(time.time() * 1000)
    chunk_ms = CHUNK_HOURS * 3600 * 1000

    for coin in COINS:
        for interval in INTERVALS:

            key = f"{coin}-{interval}"
            print(f"\nğŸš€ Start: {key}")

            # åˆå§‹åŒ–èµ·ç‚¹
            if key not in ckpt:
                start_ms = now_ms - YEARS_BACK * 365 * 24 * 3600 * 1000
            else:
                start_ms = ckpt[key]

            while start_ms < now_ms:
                end_ms = min(start_ms + chunk_ms, now_ms)

                print(f"â± {coin} {interval} | {datetime.utcfromtimestamp(start_ms/1000)} â†’ {datetime.utcfromtimestamp(end_ms/1000)}")

                data = safe_call_with_retry(
                    info.candles_snapshot,
                    name=coin,
                    interval=interval,
                    startTime=int(start_ms),
                    endTime=int(end_ms),
                )


                if data:
                    df = pd.DataFrame(data)

                    os.makedirs(f"{DATA_DIR}/{coin}", exist_ok=True)
                    out_path = f"{DATA_DIR}/{coin}/{interval}.parquet"
                    save_parquet_incremental(out_path, df)

                # æ›´æ–°æ–­ç‚¹
                ckpt[key] = end_ms
                save_checkpoint(ckpt)

                start_ms = end_ms
                time.sleep(API_SLEEP)


if __name__ == "__main__":
    fetch_all()
